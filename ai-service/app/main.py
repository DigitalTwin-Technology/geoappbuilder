"""
MapForge AI Service - Text-to-SQL and Text-to-Style Generation

Per .cursorrules:
- Stateless service: Receives prompt -> Returns SQL/JSON
- Does NOT touch DB directly
- Uses standard PostGIS syntax for SQL generation
"""

import os
import json
import re
from typing import Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

import google.generativeai as genai

# Configure Gemini API
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyAGBr0HzNexgBMaheJfN62792DGjInVTEc")
genai.configure(api_key=GEMINI_API_KEY)

# Initialize Gemini model - try different model names for compatibility
MODEL_NAME = "gemini-2.0-flash"
model = genai.GenerativeModel(MODEL_NAME)

app = FastAPI(
    title="MapForge AI Service",
    description="AI service for SQL and style generation using Gemini",
    version="0.2.0",
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000", "http://localhost:8080", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class SQLGenerationRequest(BaseModel):
    """Request model for SQL generation"""
    prompt: str = Field(..., min_length=1, max_length=1000, description="Natural language prompt")
    context: Optional[str] = Field(None, description="Additional context about the data schema")
    table_name: Optional[str] = Field(None, description="Target table name")


class SQLGenerationResponse(BaseModel):
    """Response model for SQL generation"""
    sql: str
    explanation: str
    confidence: float = Field(ge=0.0, le=1.0)
    timestamp: str
    warning: Optional[str] = None


class StyleGenerationRequest(BaseModel):
    """Request model for map style generation"""
    prompt: str = Field(..., min_length=1, max_length=1000)
    layer_type: str = Field(default="fill", pattern="^(fill|line|circle|symbol|heatmap)$")
    current_style: Optional[dict] = None


class StyleGenerationResponse(BaseModel):
    """Response model for map style generation"""
    style: dict
    explanation: str
    timestamp: str


class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    service: str
    timestamp: str
    gemini_configured: bool


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        service="ai-service",
        timestamp=datetime.utcnow().isoformat(),
        gemini_configured=bool(GEMINI_API_KEY)
    )


@app.post("/generate-sql", response_model=SQLGenerationResponse)
async def generate_sql(request: SQLGenerationRequest):
    """
    Generate SQL query from natural language prompt using Gemini.
    """
    if not request.prompt.strip():
        raise HTTPException(status_code=400, detail="Prompt cannot be empty")
    
    table = request.table_name or "features"
    
    system_prompt = f"""You are a PostGIS SQL expert. Generate a valid PostgreSQL/PostGIS query based on the user's request.

Table schema:
- Table name: {table}
- Columns: id (UUID), geometry (GEOMETRY), properties (JSONB), name (TEXT), created_at (TIMESTAMP)
- The geometry column uses SRID 4326 (WGS84)

Rules:
1. Always use PostGIS functions for spatial operations (ST_Intersects, ST_DWithin, ST_Area, etc.)
2. Return geometry as GeoJSON using ST_AsGeoJSON
3. Use parameterized queries where appropriate ($1, $2, etc.)
4. Add LIMIT clause to prevent returning too many rows
5. Only return the SQL query, no explanations in the SQL itself

Return your response in this exact JSON format:
{{"sql": "YOUR SQL QUERY HERE", "explanation": "Brief explanation of what the query does"}}
"""

    try:
        response = model.generate_content(
            f"{system_prompt}\n\nUser request: {request.prompt}"
        )
        
        # Parse the response
        response_text = response.text.strip()
        
        # Try to extract JSON from the response
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            result = json.loads(json_match.group())
            sql = result.get("sql", "")
            explanation = result.get("explanation", "Generated by Gemini AI")
        else:
            # Fallback: treat entire response as SQL
            sql = response_text
            explanation = "Generated by Gemini AI"
        
        return SQLGenerationResponse(
            sql=sql.strip(),
            explanation=explanation,
            confidence=0.85,
            timestamp=datetime.utcnow().isoformat(),
            warning=None
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI generation failed: {str(e)}")


def generate_style_from_keywords(prompt: str, layer_type: str) -> tuple[dict, str]:
    """
    Generate style based on keywords in prompt (fallback when API is unavailable).
    """
    prompt_lower = prompt.lower()
    
    # Color keywords
    colors = {
        "red": "#ef4444", "orange": "#f97316", "yellow": "#eab308", "green": "#22c55e",
        "blue": "#3b82f6", "purple": "#8b5cf6", "pink": "#ec4899", "white": "#ffffff",
        "black": "#000000", "gray": "#6b7280", "grey": "#6b7280", "cyan": "#06b6d4",
        "teal": "#14b8a6", "indigo": "#6366f1", "violet": "#8b5cf6", "emerald": "#10b981",
        "ocean": "#0ea5e9", "sky": "#38bdf8", "sunset": "#f97316", "forest": "#166534",
        "gold": "#eab308", "bronze": "#cd7f32", "silver": "#c0c0c0", "coral": "#f97316"
    }
    
    # Find color in prompt
    fill_color = "#3b82f6"  # Default blue
    for color_name, color_hex in colors.items():
        if color_name in prompt_lower:
            fill_color = color_hex
            break
    
    # Find opacity keywords
    opacity = 0.7  # Default
    if "transparent" in prompt_lower or "transparency" in prompt_lower:
        opacity = 0.5
    if "50%" in prompt_lower:
        opacity = 0.5
    if "25%" in prompt_lower:
        opacity = 0.25
    if "75%" in prompt_lower:
        opacity = 0.75
    if "solid" in prompt_lower or "bold" in prompt_lower:
        opacity = 1.0
    
    # Find border/outline keywords
    border_color = "#1f2937"  # Default dark
    for color_name, color_hex in colors.items():
        if f"{color_name} border" in prompt_lower or f"{color_name} outline" in prompt_lower:
            border_color = color_hex
            break
    if "dark border" in prompt_lower or "dark outline" in prompt_lower:
        border_color = "#1f2937"
    if "white border" in prompt_lower or "white outline" in prompt_lower:
        border_color = "#ffffff"
    
    # Build style based on layer type
    if layer_type == "fill":
        style = {
            "fill-color": fill_color,
            "fill-opacity": opacity,
            "fill-outline-color": border_color
        }
        explanation = f"Fill style with {fill_color} color and {int(opacity*100)}% opacity"
    elif layer_type == "line":
        width = 3 if "thick" in prompt_lower or "bold" in prompt_lower else 2
        style = {
            "line-color": fill_color,
            "line-width": width,
            "line-opacity": opacity
        }
        explanation = f"Line style with {fill_color} color"
    else:  # circle
        radius = 8 if "large" in prompt_lower or "big" in prompt_lower else 6
        style = {
            "circle-radius": radius,
            "circle-color": fill_color,
            "circle-opacity": opacity,
            "circle-stroke-color": border_color,
            "circle-stroke-width": 2
        }
        explanation = f"Circle style with {fill_color} color"
    
    return style, explanation


@app.post("/generate-style", response_model=StyleGenerationResponse)
async def generate_style(request: StyleGenerationRequest):
    """
    Generate MapLibre layer style from natural language prompt using Gemini.
    Falls back to keyword-based generation if API quota is exceeded.
    """
    if not request.prompt.strip():
        raise HTTPException(status_code=400, detail="Prompt cannot be empty")
    
    system_prompt = f"""You are a MapLibre GL style expert. Generate a valid MapLibre paint style object based on the user's description.

The layer type is: {request.layer_type}

Valid paint properties by layer type:
- fill: fill-color, fill-opacity, fill-outline-color, fill-pattern
- line: line-color, line-width, line-opacity, line-blur, line-dasharray, line-cap, line-join
- circle: circle-radius, circle-color, circle-blur, circle-opacity, circle-stroke-width, circle-stroke-color
- symbol: icon-color, icon-size, text-color, text-size, text-halo-color, text-halo-width
- heatmap: heatmap-radius, heatmap-weight, heatmap-intensity, heatmap-color, heatmap-opacity

Rules:
1. Colors should be valid CSS colors (hex, rgb, rgba, or named colors)
2. Opacity values should be between 0 and 1
3. Use realistic values that would look good on a map
4. Be creative with the style based on the user's description
5. Return ONLY valid JSON, no markdown or extra text

Return your response in this exact JSON format:
{{"style": {{"property-name": "value"}}, "explanation": "Brief description of the style"}}

Examples:
- For "make it red and bold": {{"style": {{"fill-color": "#ef4444", "fill-opacity": 0.8}}, "explanation": "Bold red fill style"}}
- For "ocean blue with transparency": {{"style": {{"fill-color": "#0ea5e9", "fill-opacity": 0.5}}, "explanation": "Transparent ocean blue"}}
"""

    try:
        response = model.generate_content(
            f"{system_prompt}\n\nUser request: {request.prompt}"
        )
        
        response_text = response.text.strip()
        
        # Try to extract JSON from the response
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if json_match:
            result = json.loads(json_match.group())
            style = result.get("style", {})
            explanation = result.get("explanation", "Style generated by Gemini AI")
        else:
            # Fallback to default style
            style = get_default_style(request.layer_type)
            explanation = "Default style (AI parsing failed)"
        
        # Validate and ensure style has required properties
        if not style:
            style = get_default_style(request.layer_type)
        
        return StyleGenerationResponse(
            style=style,
            explanation=explanation,
            timestamp=datetime.utcnow().isoformat()
        )
    except json.JSONDecodeError:
        # Return default style on JSON parse error
        return StyleGenerationResponse(
            style=get_default_style(request.layer_type),
            explanation="Default style applied (JSON parsing error)",
            timestamp=datetime.utcnow().isoformat()
        )
    except Exception as e:
        # If quota exceeded or other API error, use keyword-based fallback
        error_str = str(e).lower()
        if "429" in error_str or "quota" in error_str or "rate" in error_str:
            style, explanation = generate_style_from_keywords(request.prompt, request.layer_type)
            return StyleGenerationResponse(
                style=style,
                explanation=f"{explanation} (generated from keywords)",
                timestamp=datetime.utcnow().isoformat()
            )
        raise HTTPException(status_code=500, detail=f"AI generation failed: {str(e)}")


def get_default_style(layer_type: str) -> dict:
    """Return default style for a layer type"""
    defaults = {
        "fill": {
            "fill-color": "#3b82f6",
            "fill-opacity": 0.6,
            "fill-outline-color": "#1e40af"
        },
        "line": {
            "line-color": "#ef4444",
            "line-width": 2,
            "line-opacity": 0.8
        },
        "circle": {
            "circle-radius": 6,
            "circle-color": "#10b981",
            "circle-stroke-color": "#ffffff",
            "circle-stroke-width": 2
        },
        "symbol": {
            "icon-size": 1.0,
            "text-size": 12,
            "text-color": "#1f2937"
        },
        "heatmap": {
            "heatmap-weight": 1,
            "heatmap-intensity": 1,
            "heatmap-radius": 30,
            "heatmap-opacity": 0.8
        }
    }
    return defaults.get(layer_type, defaults["fill"])


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(app, host="0.0.0.0", port=port)
